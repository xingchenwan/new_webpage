<!DOCTYPE html>
<html lang="en">
  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <!-- Metadata, OpenGraph and Schema.org -->




<!-- Standard metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title>
  
  
    
      publications | Xingchen Wan
    
  
</title>
<meta name="author" content="Xingchen Wan">
<meta name="description" content="publications by categories in reversed chronological order. generated by jekyll-scholar.">










<!-- Bootstrap & MDB -->
<link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">



<!-- Fonts & Icons -->
<link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5">
<link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772">
<link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap">

<!-- Code Syntax Highlighting -->
<link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light">



<!-- Styles -->




  <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8C%9F&lt;/text&gt;&lt;/svg&gt;">

<link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e">
<link rel="canonical" href="https://xingchen.one/publications/">


  <!-- Dark Mode -->
  <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script>
  <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark">
  <script>
    initTheme();
  </script>










  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">
    <!-- Header -->
    <header>
  <!-- Nav Bar -->
  <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation">
    <div class="container">
      
        <a class="navbar-brand title font-weight-lighter" href="/">
          
            
              <span class="font-weight-bold">Xingchen</span>
            
            
            Wan
          
        </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>

      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          

          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">about
              
            </a>
          </li>

          <!-- Other pages -->
          
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
              
                
                <li class="nav-item active">
                  <a class="nav-link" href="/publications/">publications
                    
                      <span class="sr-only">(current)</span>
                    
                  </a>
                </li>
              
            
          
          
            <!-- Search -->
            <li class="nav-item">
              <button id="search-toggle" title="Search" onclick="openSearchModal()">
                <span class="nav-link">ctrl k <i class="ti ti-search"></i></span>
              </button>
            </li>
          
          
            <!-- Toogle theme mode -->
            <li class="toggle-container">
              <button id="light-toggle" title="Change theme">
                <i class="ti ti-sun-moon" id="light-toggle-system"></i>
                <i class="ti ti-moon-filled" id="light-toggle-dark"></i>
                <i class="ti ti-sun-filled" id="light-toggle-light"></i>
              </button>
            </li>
          
        </ul>
      </div>
    </div>
  </nav>
  
    <!-- Scrolling Progress Bar -->
    <progress id="progress" value="0">
      <div class="progress-container">
        <span class="progress-bar"></span>
      </div>
    </progress>
  
</header>


    <!-- Content -->
    <div class="container mt-5" role="main">
      
        

<div class="post">
  <header class="post-header">
    <h1 class="post-title">publications</h1>
    <p class="post-description">publications by categories in reversed chronological order. generated by jekyll-scholar.</p>
  </header>

  <article>
    <!-- _pages/publications.md -->

<!-- Bibsearch Feature -->

<script src="/assets/js/bibsearch.js?1bc438ca9037884cc579601c09afd847" type="module"></script>

<p><input type="text" id="bibsearch" spellcheck="false" autocomplete="off" class="search bibsearch-form-input" placeholder="Type to filter"></p>

<div class="publications">

<h2 class="bibliography">2026</h2>
<ol class="bibliography">
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100" style="background-color:#00369f">
            
              <a href="https://arXiv.org" rel="external nofollow noopener" target="_blank">arXiv</a>
            
          </abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="lin2026largelanguagemodelsgeneralize" class="col-sm-8">
    <!-- Title -->
    <div class="title">Can Large Language Models Generalize Procedures Across Representations?</div>
    <!-- Author -->
    <div class="author">
      

      
      Fangru
            Lin, Valentin
            Hofmann, <em>Xingchen
            Wan</em>, Weixing
            Wang, Zifeng
            Ding, Anthony G.
            Cohn, and Janet B.
            Pierrehumbert
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em></em> 2026
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
        
          <a href="https://arxiv.org/pdf/2602.03542" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Large language models (LLMs) are trained and tested extensively on symbolic representations such as code and graphs, yet real-world user tasks are often specified in natural language. To what extent can LLMs generalize across these representations? Here, we approach this question by studying isomorphic tasks involving procedures represented in code, graphs, and natural language (e.g., scheduling steps in planning). We find that training LLMs with popular post-training methods on graphs or code data alone does not reliably generalize to corresponding natural language tasks, while training solely on natural language can lead to inefficient performance gains. To address this gap, we propose a two-stage data curriculum that first trains on symbolic, then natural language data. The curriculum substantially improves model performance across model families and tasks. Remarkably, a 1.5B Qwen model trained by our method can closely match zero-shot GPT-4o in naturalistic planning. Finally, our analysis suggests that successful cross-representation generalization can be interpreted as a form of generative analogy, which our curriculum effectively encourages.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">ICLR 2026</abbr>
        
      
      
        
          
          



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      
    
    <img src="/assets/img/publication_preview/vprl.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="vprl.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

        
      
    </div>
  

  <!-- Entry bib key -->
  <div id="xu2025visualplanningletsthink" class="col-sm-8">
    <!-- Title -->
    <div class="title">Visual Planning: Let‚Äôs Think Only with Images</div>
    <!-- Author -->
    <div class="author">
      

      
      Yi
            Xu<sup>*</sup>, Chengzu
            Li<sup>*</sup>, Han
            Zhou<sup>*</sup>, <em>Xingchen
            Wan</em>, Caiqi
            Zhang, Anna
            Korhonen, and Ivan
            Vuliƒá
      
        <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* equal contribution">
        </i>
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>The Fourteenth International Conference on Learning Representations (to appear)</em>.  üèÜü•â <strong>#3 paper of the day at <a href="https://huggingface.co/papers/2505.11409" rel="external nofollow noopener" target="_blank">HuggingFace ü§ó</a></strong>
,  2026
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
        
          <a href="https://arxiv.org/pdf/2505.11409" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
        <a href="https://github.com/yix8/VisualPlanning" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
        <div class="badges">
          
          
          
            <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=6KkohssAAAAJ&amp;citation_for_view=6KkohssAAAAJ:dshw04ExmUIC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
              <img src="https://img.shields.io/badge/scholar-37-4285F4?logo=googlescholar&amp;labelColor=beige" alt="37 Google Scholar citations">
            </a>
          
          
        </div>
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Recent advancements in Large Language Models (LLMs) and their multimodal extensions (MLLMs) have substantially enhanced machine reasoning across diverse tasks. However, these models predominantly rely on pure text as the medium for both expressing and structuring reasoning, even when visual information is present. In this work, we argue that language may not always be the most natural or effective modality for reasoning, particularly in tasks involving spatial and geometrical information. Motivated by this, we propose a new paradigm, Visual Planning, which enables planning through purely visual representations, independent of text. In this paradigm, planning is executed via sequences of images that encode step-by-step inference in the visual domain, akin to how humans sketch or visualize future actions. We introduce a novel reinforcement learning framework, Visual Planning via Reinforcement Learning (VPRL), empowered by GRPO for post-training large vision models, leading to substantial improvements in planning in a selection of representative visual navigation tasks, FrozenLake, Maze, and MiniBehavior. Our visual planning paradigm outperforms all other planning variants that conduct reasoning in the text-only space. Our results establish Visual Planning as a viable and promising alternative to language-based reasoning, opening new avenues for tasks that benefit from intuitive, image-based inference.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">ICLR 2026</abbr>
        
      
      
        
          
          



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      
    
    <img src="/assets/img/publication_preview/mass.jpeg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="mass.jpeg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

        
      
    </div>
  

  <!-- Entry bib key -->
  <div id="zhou2025multiagentdesignoptimizingagents" class="col-sm-8">
    <!-- Title -->
    <div class="title">Multi-Agent Design: Optimizing Agents with Better Prompts and Topologies</div>
    <!-- Author -->
    <div class="author">
      

      
      Han
            Zhou, <em>Xingchen
            Wan</em>, Ruoxi
            Sun, Hamid
            Palangi, Shariq
            Iqbal, Ivan
            Vuliƒá, Anna
            Korhonen, and Sercan √ñ.
            Arƒ±k
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>The Fourteenth International Conference on Learning Representations (to appear)</em>,  2026
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
        <a href="https://doi.org/10.48550/arxiv.2502.02533" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a>
      
      
      
      
      
        
          <a href="https://arxiv.org/pdf/2502.02533" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
        <div class="badges">
          
            <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-arxiv-id="2502.02533"></span>
          
          
          
            <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=6KkohssAAAAJ&amp;citation_for_view=6KkohssAAAAJ:b0M2c_1WBrUC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
              <img src="https://img.shields.io/badge/scholar-67-4285F4?logo=googlescholar&amp;labelColor=beige" alt="67 Google Scholar citations">
            </a>
          
          
        </div>
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Large language models, employed as multiple agents that interact and collaborate with each other, have excelled at solving complex tasks. The agents are programmed with prompts that declare their functionality, along with the topologies that orchestrate interactions across agents. Designing prompts and topologies for multi-agent systems (MAS) is inherently complex. To automate the entire design process, we first conduct an in-depth analysis of the design space aiming to understand the factors behind building effective MAS. We reveal that prompts together with topologies play critical roles in enabling more effective MAS design. Based on the insights, we propose Multi-Agent System Search (MASS), a MAS optimization framework that efficiently exploits the complex MAS design space by interleaving its optimization stages, from local to global, from prompts to topologies, over three stages: 1) block-level (local) prompt optimization; 2) workflow topology optimization; 3) workflow-level (global) prompt optimization, where each stage is conditioned on the iteratively optimized prompts/topologies from former stages. We show that MASS-optimized multi-agent systems outperform a spectrum of existing alternatives by a substantial margin. Based on the MASS-found systems, we finally propose design principles behind building effective multi-agent systems.</p>
      </div>
    

    

    
  </div>
</div>
</li>
</ol>
<h2 class="bibliography">2025</h2>
<ol class="bibliography">
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100" style="background-color:#00369f">
            
              <a href="https://arXiv.org" rel="external nofollow noopener" target="_blank">arXiv</a>
            
          </abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="zhou2025agenticpolicyoptimizationinstructionpolicy" class="col-sm-8">
    <!-- Title -->
    <div class="title">Agentic Policy Optimization via Instruction-Policy Co-Evolution</div>
    <!-- Author -->
    <div class="author">
      

      
      Han
            Zhou, <em>Xingchen
            Wan</em>, Ivan
            Vuliƒá, and Anna
            Korhonen
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em></em> 2025
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
        
          <a href="https://arxiv.org/pdf/2512.01945" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Reinforcement Learning with Verifiable Rewards (RLVR) has advanced the reasoning capability of large language models (LLMs), enabling autonomous agents that can conduct effective multi-turn and tool-integrated reasoning. While instructions serve as the primary protocol for defining agents, RLVR typically relies on static and manually designed instructions. However, those instructions may be suboptimal for the base model, and the optimal instruction may change as the agent‚Äôs policy improves and explores the interaction with the environment. To bridge the gap, we introduce INSPO, a novel Instruction-Policy co-evolution framework that integrates instruction optimization as a dynamic component of the reinforcement learning (RL) loop. INSPO maintains a dynamic population of instruction candidates that are sampled with questions, where reward signals in RL loops are automatically attributed to each instruction, and low performers are periodically pruned. New instructions are generated and verified through an on-policy reflection mechanism, where an LLM-based optimizer analyzes past experience from a replay buffer and evolves more effective strategies given the current policy. We conduct extensive experiments on multi-turn retrieval and reasoning tasks, demonstrating that INSPO substantially outperforms strong baselines relying on static instructions. INSPO discovers innovative instructions that guide the agent toward more strategic reasoning paths, achieving substantial performance gains with only a marginal increase in computational overhead.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100" style="background-color:#00369f">
            
              <a href="https://arXiv.org" rel="external nofollow noopener" target="_blank">arXiv</a>
            
          </abbr>
        
      
      
        
          
          



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      
    
    <img src="/assets/img/publication_preview/vista_spaceship.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="vista_spaceship.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

        
      
    </div>
  

  <!-- Entry bib key -->
  <div id="long2025vista" class="col-sm-8">
    <!-- Title -->
    <div class="title">VISTA: A Test-Time Self-Improving Video Generation Agent</div>
    <!-- Author -->
    <div class="author">
      

      
      Do Xuan
            Long, <em>Xingchen
            Wan</em>, Hootan
            Nakhost, Chen-Yu
            Lee, Tomas
            Pfister, and Sercan √ñ.
            Arƒ±k
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>arXiv preprint arXiv:2510.15831</em>,  2025
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
        <a href="https://doi.org/10.48550/arxiv.2510.15831" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a>
      
      
      
      
      
        
          <a href="https://arxiv.org/pdf/2510.15831" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
      
      
      
        <a href="https://g-vista.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a>
      
    </div>
    
      
      

      
      

      
      

      
      
      
        <div class="badges">
          
            <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-arxiv-id="2510.15831"></span>
          
          
          
            <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=6KkohssAAAAJ&amp;citation_for_view=6KkohssAAAAJ:738O_yMBCRsC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
              <img src="https://img.shields.io/badge/scholar-2-4285F4?logo=googlescholar&amp;labelColor=beige" alt="2 Google Scholar citations">
            </a>
          
          
        </div>
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Despite rapid advances in text-to-video synthesis, generated video quality remains critically dependent on precise user prompts. Existing test-time optimization methods, successful in other domains, struggle with the multi-faceted nature of video. In this work, we introduce VISTA (Video Iterative Self-improvemenT Agent), a novel multi-agent system that autonomously improves video generation through refining prompts in an iterative loop. VISTA first decomposes a user idea into a structured temporal plan. After generation, the best video is identified through a robust pairwise tournament. This winning video is then critiqued by a trio of specialized agents focusing on visual, audio, and contextual fidelity. Finally, a reasoning agent synthesizes this feedback to introspectively rewrite and enhance the prompt for the next generation cycle. Experiments on single- and multi-scene video generation scenarios show that while prior methods yield inconsistent gains, VISTA consistently improves video quality and alignment with user intent, achieving up to 60% pairwise win rate against state-of-the-art baselines. Human evaluators concur, preferring VISTA outputs in 66.4% of comparisons.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100" style="background-color:#00369f">
            
              <a href="https://arXiv.org" rel="external nofollow noopener" target="_blank">arXiv</a>
            
          </abbr>
        
      
      
        
          
          



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      
    
    <img src="/assets/img/publication_preview/maestro.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="maestro.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

        
      
    </div>
  

  <!-- Entry bib key -->
  <div id="wan2025maestro" class="col-sm-8">
    <!-- Title -->
    <div class="title">Maestro: Self-Improving Text-to-Image Generation via Agent Orchestration</div>
    <!-- Author -->
    <div class="author">
      

      
      <em>Xingchen
            Wan</em>, Han
            Zhou, Ruoxi
            Sun, Hootan
            Nakhost, Ke
            Jiang, Rajarishi
            Sinha, and Sercan √ñ.
            Arƒ±k
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>arXiv preprint arXiv:2509.10704</em>,  2025
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
        
          <a href="https://arxiv.org/pdf/2509.10704" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
        <div class="badges">
          
          
          
            <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=6KkohssAAAAJ&amp;citation_for_view=6KkohssAAAAJ:XiSMed-E-HIC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
              <img src="https://img.shields.io/badge/scholar-4-4285F4?logo=googlescholar&amp;labelColor=beige" alt="4 Google Scholar citations">
            </a>
          
          
        </div>
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Text-to-image (T2I) models, while offering immense creative potential, are highly reliant on human intervention, posing significant usability challenges that often necessitate manual, iterative prompt engineering over often underspecified prompts. This paper introduces Maestro, a novel self-evolving image generation system that enables T2I models to autonomously self-improve generated images through iterative evolution of prompts, using only an initial prompt. Maestro incorporates two key innovations: 1) self-critique, where specialized multimodal LLM (MLLM) agents act as ‚Äôcritics‚Äô to identify weaknesses in generated images, correct for under-specification, and provide interpretable edit signals, which are then integrated by a ‚Äôverifier‚Äô agent while preserving user intent; and 2) self-evolution, utilizing MLLM-as-a-judge for head-to-head comparisons between iteratively generated images, eschewing problematic images, and evolving creative prompt candidates that align with user intents. Extensive experiments on complex T2I tasks using black-box models demonstrate that Maestro significantly improves image quality over initial prompts and state-of-the-art automated methods, with effectiveness scaling with more advanced MLLM components. This work presents a robust, interpretable, and effective pathway towards self-improving T2I generation.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100" style="background-color:#00369f">
            
              <a href="https://arXiv.org" rel="external nofollow noopener" target="_blank">arXiv</a>
            
          </abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="wang2025dynscaling" class="col-sm-8">
    <!-- Title -->
    <div class="title">DynScaling: Efficient Verifier-free Inference Scaling via Dynamic and Integrated Sampling</div>
    <!-- Author -->
    <div class="author">
      

      
      Fei
            Wang, <em>Xingchen
            Wan</em>, Ruoxi
            Sun, Jiefeng
            Chen, and Sercan √ñ.
            Arƒ±k
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>arXiv preprint arXiv:2506.16043</em>,  2025
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
        
          <a href="https://arxiv.org/pdf/2506.16043" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
        <div class="badges">
          
          
          
            <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=6KkohssAAAAJ&amp;citation_for_view=6KkohssAAAAJ:OU6Ihb5iCvQC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
              <img src="https://img.shields.io/badge/scholar-2-4285F4?logo=googlescholar&amp;labelColor=beige" alt="2 Google Scholar citations">
            </a>
          
          
        </div>
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Inference-time scaling has proven effective in boosting large language model (LLM) performance through increased test-time computation. Yet, its practical application is often hindered by reliance on external verifiers or a lack of optimization for realistic computational constraints. We propose DynScaling, which addresses these limitations through two primary innovations: an integrated parallel-sequential sampling strategy and a bandit-based dynamic budget allocation framework. The integrated sampling strategy unifies parallel and sequential sampling by constructing synthetic sequential reasoning chains from initially independent parallel responses, promoting diverse and coherent reasoning trajectories. The dynamic budget allocation framework formulates the allocation of computational resources as a multi-armed bandit problem, adaptively distributing the inference budget across queries based on the uncertainty of previously sampled responses, thereby maximizing computational efficiency. By combining these components, DynScaling effectively improves LLM performance under practical resource constraints without the need for external verifiers. Experimental results demonstrate that DynScaling consistently surpasses existing verifier-free inference scaling baselines in both task performance and computational cost.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">COLM 2025</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="pourreza2025reasoningsql" class="col-sm-8">
    <!-- Title -->
    <div class="title">Reasoning-SQL: Reinforcement Learning with SQL Tailored Partial Rewards for Reasoning-Enhanced Text-to-SQL</div>
    <!-- Author -->
    <div class="author">
      

      
      Mohammadreza
            Pourreza, Shayan
            Talaei, Ruoxi
            Sun, <em>Xingchen
            Wan</em>, Hailong
            Li, Azalia
            Mirhoseini, Amin
            Saberi, and Sercan O
            Arik
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>In Second Conference on Language Modeling</em>,  2025
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
        
          <a href="https://openreview.net/pdf?id=HbwkIDWQgN" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
        <div class="badges">
          
          
          
            <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=6KkohssAAAAJ&amp;citation_for_view=6KkohssAAAAJ:1sJd4Hv_s6UC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
              <img src="https://img.shields.io/badge/scholar-41-4285F4?logo=googlescholar&amp;labelColor=beige" alt="41 Google Scholar citations">
            </a>
          
          
        </div>
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Text-to-SQL is a challenging task involving multiple reasoning-intensive subtasks, including natural language understanding, database schema comprehension, and precise SQL query formulation. Existing approaches often rely on handcrafted reasoning paths with inductive biases that can limit their overall effectiveness. Motivated by the recent success of reasoning-enhanced models such as DeepSeek R1 and OpenAI o1, which effectively leverage reward-driven self-exploration to enhance reasoning capabilities and generalization, we propose a novel set of partial rewards tailored specifically for the Text-to-SQL task. Our reward set includes schema-linking, AI feedback, n-gram similarity, and syntax check, explicitly designed to address the reward sparsity issue prevalent in reinforcement learning (RL). Leveraging group relative policy optimization (GRPO), our approach explicitly encourages large language models (LLMs) to develop intrinsic reasoning skills necessary for accurate SQL query generation. With models of different sizes, we demonstrate that RL-only training with our proposed rewards consistently achieves higher accuracy and superior generalization compared to supervised fine-tuning (SFT). Remarkably, our RL-trained 14B-parameter model significantly outperforms larger proprietary models, e.g. o3-mini by 4% and Gemini-1.5-Pro-002 by 3% on the BIRD benchmark. These highlight the efficacy of our proposed RL-training framework with partial rewards for enhancing both accuracy and reasoning capabilities in Text-to-SQL tasks.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">ICLR 2025</abbr>
        
      
      
        
          
          



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      
    
    <img src="/assets/img/publication_preview/bridge.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="bridge.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

        
      
    </div>
  

  <!-- Entry bib key -->
  <div id="wan2025selfimproving" class="col-sm-8">
    <!-- Title -->
    <div class="title">From Few to Many: Self-Improving Many-Shot Reasoners Through Iterative Optimization and Generation</div>
    <!-- Author -->
    <div class="author">
      

      
      <em>Xingchen
            Wan</em>, Han
            Zhou, Ruoxi
            Sun, Hootan
            Nakhost, Ke
            Jiang, and Sercan √ñ.
            Arƒ±k
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>In The Thirteenth International Conference on Learning Representations</em>,  2025
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
        
          <a href="https://arxiv.org/pdf/2502.00330" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
        <div class="badges">
          
          
          
            <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=6KkohssAAAAJ&amp;citation_for_view=6KkohssAAAAJ:EUQCXRtRnyEC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
              <img src="https://img.shields.io/badge/scholar-12-4285F4?logo=googlescholar&amp;labelColor=beige" alt="12 Google Scholar citations">
            </a>
          
          
        </div>
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Recent advances in long-context large language models (LLMs) have led to the emerging paradigm of many-shot in-context learning (ICL), where it is observed that scaling many more demonstrating examples beyond the conventional few-shot setup in the context can lead to performance benefits. However, despite its promise, it is unclear what aspects dominate the benefits and whether simply scaling to more examples is the most effective way of improving many-shot ICL. In this work, we first provide an analysis of the factors driving many-shot ICL, and we find that 1) many-shot performance can still be attributed to often a few disproportionately influential examples and 2) identifying such influential examples ("optimize") and using them as demonstrations to regenerate new examples ("generate") can lead to further improvements. Inspired by the findings, we propose BRIDGE, an algorithm that alternates between the optimize step with Bayesian optimization to discover the influential sets of examples and the generate step to reuse this set to expand the reasoning paths of the examples back to the many-shot regime automatically. On Gemini, Claude, and Mistral LLMs of different sizes, we show that BRIDGE to significant improvements across a diverse set of tasks, including symbolic reasoning, numerical reasoning, and code generation.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">ACL 2025</abbr>
        
      
      
        
          
          



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      
    
    <img src="/assets/img/publication_preview/astuterag.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="astuterag.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

        
      
    </div>
  

  <!-- Entry bib key -->
  <div id="wang-etal-2025-astute" class="col-sm-8">
    <!-- Title -->
    <div class="title">Astute RAG: Overcoming Imperfect Retrieval Augmentation and Knowledge Conflicts for Large Language Models</div>
    <!-- Author -->
    <div class="author">
      

      
      Fei
            Wang, <em>Xingchen
            Wan</em>, Ruoxi
            Sun, Jiefeng
            Chen, and Sercan O
            Arik
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>,  2025
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
        <a href="https://doi.org/10.48550/arxiv.2410.07176" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a>
      
      
      
      
      
        
          <a href="https://aclanthology.org/2025.acl-long.1476.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
        <div class="badges">
          
            <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-doi="10.48550/arxiv.2410.07176"></span>
          
          
          
            <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=6KkohssAAAAJ&amp;citation_for_view=6KkohssAAAAJ:a0OBvERweLwC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
              <img src="https://img.shields.io/badge/scholar-100-4285F4?logo=googlescholar&amp;labelColor=beige" alt="100 Google Scholar citations">
            </a>
          
          
        </div>
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Retrieval augmented generation (RAG), while effectively integrating external knowledge to address the inherent limitations of large language models (LLMs), can be hindered by imperfect retrieval that contain irrelevant, misleading, or even malicious information. Previous studies have rarely connected the behavior of RAG through joint analysis, particularly regarding error propagation coming from imperfect retrieval and potential conflicts between LLMs‚Äô internal knowledge and external sources. Through comprehensive and controlled analyses under realistic conditions, we find that imperfect retrieval augmentation is inevitable, common, and harmful. We identify the knowledge conflicts between LLM-internal and external knowledge from retrieval as a bottleneck to overcome imperfect retrieval in the post-retrieval stage of RAG. To address this, we propose Astute RAG, a novel RAG approach designed to be resilient to imperfect retrieval augmentation. It adaptively elicits essential information from LLMs‚Äô internal knowledge, iteratively consolidates internal and external knowledge with source-awareness, and finalizes the answer according to information reliability. Our experiments with Gemini and Claude demonstrate the superior performance of Astute RAG compared to previous robustness-enhanced RAG approaches. Specifically, Astute RAG is the only RAG method that achieves performance comparable to or even surpassing conventional use of LLMs under the worst-case scenario. Further analysis reveals the effectiveness of Astute RAG in resolving knowledge conflicts, thereby improving the trustworthiness of RAG.</p>
      </div>
    

    

    
  </div>
</div>
</li>
</ol>
<h2 class="bibliography">2024</h2>
<ol class="bibliography">
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">NeurIPS 2024</abbr>
        
      
      
        
          
          



<figure>
  <picture>
    <!-- Auto scaling with imagemagick -->
    <!--
      See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
      https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
    -->
    
      
    
    <img src="/assets/img/publication_preview/ioes.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ioes.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

  
</figure>

        
      
    </div>
  

  <!-- Entry bib key -->
  <div id="Wan2024TeachBetter" class="col-sm-8">
    <!-- Title -->
    <div class="title">Teach Better or Show Smarter? On Instructions and Exemplars in Automatic Prompt Optimization</div>
    <!-- Author -->
    <div class="author">
      

      
      <em>Xingchen
            Wan</em>, Ruoxi
            Sun, Hootan
            Nakhost, and Sercan √ñ.
            Arik
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>In Advances in Neural Information Processing Systems 37</em>. ‚òÅÔ∏è <strong>Powers the <a href="https://cloud.google.com/blog/products/ai-machine-learning/announcing-vertex-ai-prompt-optimizer" rel="external nofollow noopener" target="_blank">Google Cloud Vertex AI Prompt Optimizer</a></strong>
,  2024
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
        
          <a href="https://proceedings.neurips.cc/paper_files/paper/2024/file/6b031defd145b02bed031093d8797bb3-Paper-Conference.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
        <div class="badges">
          
          
          
            <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=6KkohssAAAAJ&amp;citation_for_view=6KkohssAAAAJ:u_35RYKgDlwC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
              <img src="https://img.shields.io/badge/scholar-30-4285F4?logo=googlescholar&amp;labelColor=beige" alt="30 Google Scholar citations">
            </a>
          
          
        </div>
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Large language models have demonstrated remarkable capabilities but their performance is heavily reliant on effective prompt engineering. Automatic prompt optimization (APO) methods are designed to automate this and can be broadly categorized into those targeting instructions (instruction optimization, IO) vs. those targeting exemplars (exemplar optimization, EO). Despite their shared objective, these have evolved rather independently, with IO receiving more research attention recently. This paper seeks to bridge this gap by comprehensively comparing the performance of representative IO and EO techniques both isolation and combination on a diverse set of challenging tasks. Our findings reveal that intelligently reusing model-generated input-output pairs obtained from evaluating prompts on the validation set as exemplars, consistently improves performance on top of IO methods but is currently under-investigated. We also find that despite the recent focus on IO, how we select exemplars can outweigh how we optimize instructions, with EO strategies as simple as random search outperforming state-of-the-art IO methods with seed instructions without any optimization. Moreover, we observe a synergy between EO and IO, with optimal combinations surpassing the individual contributions. We conclude that studying exemplar optimization both as a standalone method and its optimal combination with instruction optimization remain a crucial aspect of APO and deserve greater consideration in future research, even in the era of highly capable instruction-following models.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">NeurIPS 2024</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="Liang2024GraphComBO" class="col-sm-8">
    <!-- Title -->
    <div class="title">Bayesian Optimization of Functions over Node Subsets in Graphs</div>
    <!-- Author -->
    <div class="author">
      

      
      Huidong
            Liang, <em>Xingchen
            Wan</em>, and Xiaowen
            Dong
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>In Advances in Neural Information Processing Systems 37</em>,  2024
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
        
          <a href="https://arxiv.org/pdf/2405.15119" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
        <a href="https://github.com/LeonResearch/GraphComBO" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
        <div class="badges">
          
          
          
            <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=6KkohssAAAAJ&amp;citation_for_view=6KkohssAAAAJ:HoB7MX3m0LUC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
              <img src="https://img.shields.io/badge/scholar-6-4285F4?logo=googlescholar&amp;labelColor=beige" alt="6 Google Scholar citations">
            </a>
          
          
        </div>
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>We address the problem of optimizing over functions defined on node subsets in a graph. The optimization of such functions is often a non-trivial task given their combinatorial, black-box and expensive-to-evaluate nature. Although various algorithms have been introduced in the literature, most are either task-specific or computationally inefficient and only utilize information about the graph structure without considering the characteristics of the function. To address these limitations, we utilize Bayesian Optimization (BO), a sample-efficient black-box solver, and propose a novel framework for combinatorial optimization on graphs. More specifically, we map each -node subset in the original graph to a node in a new combinatorial graph and adopt a local modeling approach to efficiently traverse the latter graph by progressively sampling its subgraphs using a recursive algorithm. Extensive experiments under both synthetic and real-world setups demonstrate the effectiveness of the proposed BO framework on various types of graphs and optimization tasks, where its behavior is analyzed in detail with ablation studies.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">NeurIPS 2024</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="Dai2024UQE" class="col-sm-8">
    <!-- Title -->
    <div class="title">UQE: A Query Engine for Unstructured Databases</div>
    <!-- Author -->
    <div class="author">
      

      
      Hanjun
            Dai, Bethany Yixin
            Wang, <em>Xingchen
            Wan</em>, Bo
            Dai, Sherry
            Yang, Azade
            Nova, Pengcheng
            Yin, Phitchaya Mangpo
            Phothilimthana, Charles
            Sutton, and Dale
            Schuurmans
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>In Advances in Neural Information Processing Systems 37</em>,  2024
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
        
          <a href="https://arxiv.org/pdf/2407.09522" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
        <div class="badges">
          
          
          
            <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=6KkohssAAAAJ&amp;citation_for_view=6KkohssAAAAJ:fPk4N6BV_jEC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
              <img src="https://img.shields.io/badge/scholar-17-4285F4?logo=googlescholar&amp;labelColor=beige" alt="17 Google Scholar citations">
            </a>
          
          
        </div>
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Analytics on structured data is a mature field with many successful methods. However, most real world data exists in unstructured form, such as images and conversations. We investigate the potential of Large Language Models (LLMs) to enable unstructured data analytics. In particular, we propose a new Universal Query Engine (UQE) that directly interrogates and draws insights from unstructured data collections. This engine accepts queries in a Universal Query Language (UQL), a dialect of SQL that provides full natural language flexibility in specifying conditions and operators. The new engine leverages the ability of LLMs to conduct analysis of unstructured data, while also allowing us to exploit advances in sampling and optimization techniques to achieve efficient and accurate query execution. In addition, we borrow techniques from classical compiler theory to better orchestrate the workflow between sampling methods and foundation model calls. We demonstrate the efficiency of UQE on data analytics across different modalities, including images, dialogs and reviews, across a range of useful query types, including conditional aggregation, semantic retrieval and abstraction aggregation.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">EMNLP 2024</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="zhou-etal-2024-fairer" class="col-sm-8">
    <!-- Title -->
    <div class="title">Fairer Preferences Elicit Improved Human-Aligned Large Language Model Judgments</div>
    <!-- Author -->
    <div class="author">
      

      
      Han
            Zhou, <em>Xingchen
            Wan</em>, Yinhong
            Liu, Nigel
            Collier, Ivan
            Vuliƒá, and Anna
            Korhonen
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing</em>,  2024
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
        <a href="https://doi.org/10.18653/v1/2024.emnlp-main.72" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a>
      
      
      
      
      
        
          <a href="https://aclanthology.org/2024.emnlp-main.72.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
        <a href="https://github.com/cambridgeltl/zepo" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
        <div class="badges">
          
          
          
            <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=6KkohssAAAAJ&amp;citation_for_view=6KkohssAAAAJ:ZHo1McVdvXMC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
              <img src="https://img.shields.io/badge/scholar-25-4285F4?logo=googlescholar&amp;labelColor=beige" alt="25 Google Scholar citations">
            </a>
          
          
        </div>
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Large language models (LLMs) have shown promising abilities as cost-effective and reference-free evaluators for assessing language generation quality. In particular, pairwise LLM evaluators, which compare two generated texts and determine the preferred one, have been employed in a wide range of applications. However, LLMs exhibit preference biases and worrying sensitivity to prompt designs. In this work, we first reveal that the predictive preference of LLMs can be highly brittle and skewed, even with semantically equivalent instructions. We find that fairer predictive preferences from LLMs consistently lead to judgments that are better aligned with humans. Motivated by this phenomenon, we propose an automatic Zero-shot Evaluation-oriented Prompt Optimization framework, ZEPO, which aims to produce fairer preference decisions and improve the alignment of LLM evaluators with human judgments. To this end, we propose a zero-shot learning objective based on the preference decision fairness. ZEPO demonstrates substantial performance improvements over state-of-the-art LLM evaluators, without requiring labeled data, on representative meta-evaluation benchmarks. Our findings underscore the critical correlation between preference fairness and human alignment, positioning ZEPO as an efficient prompt optimizer for bridging the gap between LLM evaluators and human judgments.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">ICLR 2024</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="Zhou2024BatchCalibration" class="col-sm-8">
    <!-- Title -->
    <div class="title">Batch Calibration: Rethinking Calibration for In-Context Learning and Prompt Engineering</div>
    <!-- Author -->
    <div class="author">
      

      
      Han
            Zhou, <em>Xingchen
            Wan</em>, Lev
            Proleev, Diana
            Mincu, Jilin
            Chen, Katherine
            Heller, and Subhrajit
            Roy
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>In International Conference on Learning Representations (ICLR)</em>. üìù <strong>Featured in <a href="https://research.google/blog/batch-calibration-rethinking-calibration-for-in-context-learning-and-prompt-engineering/" rel="external nofollow noopener" target="_blank">Google Research Blog</a></strong>
,  2024
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
        
          <a href="https://arxiv.org/pdf/2309.17249" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
        <div class="badges">
          
          
          
            <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=6KkohssAAAAJ&amp;citation_for_view=6KkohssAAAAJ:lSLTfruPkqcC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
              <img src="https://img.shields.io/badge/scholar-92-4285F4?logo=googlescholar&amp;labelColor=beige" alt="92 Google Scholar citations">
            </a>
          
          
        </div>
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Prompting and in-context learning (ICL) have become efficient learning paradigms for large language models (LLMs). However, LLMs suffer from prompt brittleness and various bias factors in the prompt, including but not limited to the formatting, the choice verbalizers, and the ICL examples. To address this problem that results in unexpected performance degradation, calibration methods have been developed to mitigate the effects of these biases while recovering LLM performance. In this work, we first conduct a systematic analysis of the existing calibration methods, where we both provide a unified view and reveal the failure cases. Inspired by these analyses, we propose Batch Calibration (BC), a simple yet intuitive method that controls the contextual bias from the batched input, unifies various prior approaches, and effectively addresses the aforementioned issues. BC is zero-shot, inference-only, and incurs negligible additional costs. In the few-shot setup, we further extend BC to allow it to learn the contextual bias from labeled data. We validate the effectiveness of BC with PaLM 2-(S, M, L) and CLIP models and demonstrate state-of-the-art performance over previous calibration baselines across more than 10 natural language understanding and image classification tasks.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">AISTATS 2024</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="Adachi2024Adaptive" class="col-sm-8">
    <!-- Title -->
    <div class="title">Adaptive Batch Sizes for Active Learning: A Probabilistic Numerics Approach</div>
    <!-- Author -->
    <div class="author">
      

      
      Masaki
            Adachi, Satoshi
            Hayakawa, Martin
            J√∏rgensen, <em>Xingchen
            Wan</em>, Vu
            Nguyen, Harald
            Oberhauser, and Michael A
            Osborne
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>In Proceedings of the 27th International Conference on Artificial Intelligence and Statistics</em>,  2024
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
        
          <a href="https://proceedings.mlr.press/v238/adachi24b/adachi24b.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
        <a href="https://github.com/ma921/AdaBatAL" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
        <div class="badges">
          
          
          
            <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=6KkohssAAAAJ&amp;citation_for_view=6KkohssAAAAJ:O3NaXMp0MMsC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
              <img src="https://img.shields.io/badge/scholar-11-4285F4?logo=googlescholar&amp;labelColor=beige" alt="11 Google Scholar citations">
            </a>
          
          
        </div>
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Active learning parallelization is widely used, but typically relies on fixing the batch size throughout experimentation. This fixed approach is inefficient because of a dynamic trade-off between cost and speed‚Äîlarger batches are more costly, smaller batches lead to slower wall-clock run-times‚Äîand the trade-off may change over the run (larger batches are often preferable earlier). To address this trade-off, we propose a novel Probabilistic Numerics framework that adaptively changes batch sizes. By framing batch selection as a quadrature task, our integration-error-aware algorithm facilitates the automatic tuning of batch sizes to meet predefined quadrature precision objectives, akin to how typical optimizers terminate based on convergence thresholds. This approach obviates the necessity for exhaustive searches across all potential batch sizes. We also extend this to scenarios with constrained active learning and constrained optimization, interpreting constraint violations as reductions in the precision requirement, to subsequently adapt batch construction. Through extensive experiments, we demonstrate that our approach significantly enhances learning efficiency and flexibility in diverse Bayesian batch active learning and Bayesian optimization applications.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">AAAI 2024</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="Gong2024WorkingMemory" class="col-sm-8">
    <!-- Title -->
    <div class="title">Working Memory Capacity of ChatGPT: An Empirical Study</div>
    <!-- Author -->
    <div class="author">
      

      
      Dongyu
            Gong, <em>Xingchen
            Wan</em>, and Dingmin
            Wang
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>In Proceedings of the AAAI Conference on Artificial Intelligence</em>,  2024
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
        <a href="https://doi.org/10.1609/aaai.v38i9.28868" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a>
      
      
      
      
      
        
          <a href="https://arxiv.org/pdf/2305.03731" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
        <a href="https://github.com/Daniel-Gong/ChatGPT-WM" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
        <div class="badges">
          
          
          
            <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=6KkohssAAAAJ&amp;citation_for_view=6KkohssAAAAJ:J_g5lzvAfSwC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
              <img src="https://img.shields.io/badge/scholar-31-4285F4?logo=googlescholar&amp;labelColor=beige" alt="31 Google Scholar citations">
            </a>
          
          
        </div>
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Working memory is a critical aspect of both human intelligence and artificial intelligence, serving as a workspace for the temporary storage and manipulation of information. In this paper, we systematically assess the working memory capacity of ChatGPT, a large language model developed by OpenAI, by examining its performance in verbal and spatial n-back tasks under various conditions. Our experiments reveal that ChatGPT has a working memory capacity limit strikingly similar to that of humans. Furthermore, we investigate the impact of different instruction strategies on ChatGPT‚Äôs performance and observe that the fundamental patterns of a capacity limit persist. From our empirical findings, we propose that n-back tasks may serve as tools for benchmarking the working memory capacity of large language models and hold potential for informing future efforts aimed at enhancing AI working memory.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">TACL 2024</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="zhou2024autopeft" class="col-sm-8">
    <!-- Title -->
    <div class="title">AutoPEFT: Automatic Configuration Search for Parameter-Efficient Fine-Tuning</div>
    <!-- Author -->
    <div class="author">
      

      
      Han
            Zhou<sup>*</sup>, <em>Xingchen
            Wan<sup>*</sup></em>, Ivan
            Vuliƒá, and Anna
            Korhonen
      
        <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* equal contribution">
        </i>
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>Transactions of the Association for Computational Linguistics</em>,  2024
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
        <a href="https://doi.org/10.1162/tacl_a_00662" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a>
      
      
      
      
      
        
          <a href="https://aclanthology.org/2024.tacl-1.29.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
        <a href="https://github.com/cambridgeltl/autopeft" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
        <div class="badges">
          
          
            <span class="__dimensions_badge_embed__" data-doi="10.1162/tacl_a_00662" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          
          
            <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=6KkohssAAAAJ&amp;citation_for_view=6KkohssAAAAJ:TFP_iSt0sucC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
              <img src="https://img.shields.io/badge/scholar-81-4285F4?logo=googlescholar&amp;labelColor=beige" alt="81 Google Scholar citations">
            </a>
          
          
        </div>
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Large pretrained language models are widely used in downstream NLP tasks via task- specific fine-tuning, but such procedures can be costly. Recently, Parameter-Efficient Fine-Tuning (PEFT) methods have achieved strong task performance while updating much fewer parameters than full model fine-tuning (FFT). However, it is non-trivial to make informed design choices on the PEFT configurations, such as their architecture, the number of tunable parameters, and even the layers in which the PEFT modules are inserted. Consequently, it is highly likely that the current, manually designed configurations are suboptimal in terms of their performance-efficiency trade-off. Inspired by advances in neural architecture search, we propose AutoPEFT for automatic PEFT configuration selection: We first design an expressive configuration search space with multiple representative PEFT modules as building blocks. Using multi-objective Bayesian optimization in a low-cost setup, we then discover a Pareto-optimal set of configurations with strong performance-cost trade-offs across different numbers of parameters that are also highly transferable across different tasks. Empirically, on GLUE and SuperGLUE tasks, we show that AutoPEFT-discovered configurations significantly outperform existing PEFT methods and are on par or better than FFT without incurring substantial training efficiency costs.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">JMLR 2024</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="Granziol2022IterateAveraging" class="col-sm-8">
    <!-- Title -->
    <div class="title">Iterate Averaging in the Quest for Best Test Error</div>
    <!-- Author -->
    <div class="author">
      

      
      Diego
            Granziol<sup>*</sup>, Nick P
            Baskerville<sup>*</sup>, <em>Xingchen
            Wan<sup>*</sup></em>, Samuel
            Albanie, and Stephen
            Roberts
      
        <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* equal contribution">
        </i>
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>Journal of Machine Learning Research</em>,  2024
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
        
          <a href="https://www.jmlr.org/papers/volume25/21-1125/21-1125.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
        <a href="https://github.com/diegogranziol/Gadam" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
        <div class="badges">
          
          
          
            <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=6KkohssAAAAJ&amp;citation_for_view=6KkohssAAAAJ:0EnyYjriUFMC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
              <img src="https://img.shields.io/badge/scholar-19-4285F4?logo=googlescholar&amp;labelColor=beige" alt="19 Google Scholar citations">
            </a>
          
          
        </div>
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>We analyse and explain the increased generalisation performance of iterate averaging using a Gaussian process perturbation model between the true and batch risk surface on the high dimensional quadratic. We derive three phenomena from our theoretical results: (1) The importance of combining iterate averaging (IA) with large learning rates and regularisation for improved generalisation. (2) Justification for less frequent averaging. (3) That we expect adaptive gradient methods to work equally well, or better, with iterate averaging than their non-adaptive counterparts. Inspired by these results, together with empirical investigations of the importance of appropriate regularisation for the solution diversity of the iterates, we propose two adaptive algorithms with iterate averaging. These give significantly better results compared to stochastic gradient descent (SGD), require less tuning and do not require early stopping or validation set monitoring. We showcase the efficacy of our approach on the CIFAR-10/100, ImageNet and Penn Treebank datasets on a variety of modern and classical network architectures.</p>
      </div>
    

    

    
  </div>
</div>
</li>
</ol>
<h2 class="bibliography">2023</h2>
<ol class="bibliography">
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">NeurIPS 2023</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="wan2023bayesian" class="col-sm-8">
    <!-- Title -->
    <div class="title">Bayesian Optimisation of Functions on Graphs</div>
    <!-- Author -->
    <div class="author">
      

      
      <em>Xingchen
            Wan<sup>*</sup></em>, Pierre
            Osselin<sup>*</sup>, Henry
            Kenlay, Binxin
            Ru, Michael A
            Osborne, and Xiaowen
            Dong
      
        <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* equal contribution">
        </i>
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>In Advances in Neural Information Processing Systems 36 (NeurIPS 2023)</em>,  2023
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
        
          <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/86419aba4e5eafd2b1009a2e3c540bb0-Paper-Conference.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
        <a href="https://github.com/xingchenwan/bo-on-graph" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
        <div class="badges">
          
          
          
            <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=6KkohssAAAAJ&amp;citation_for_view=6KkohssAAAAJ:GnPB-g6toBAC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
              <img src="https://img.shields.io/badge/scholar-11-4285F4?logo=googlescholar&amp;labelColor=beige" alt="11 Google Scholar citations">
            </a>
          
          
        </div>
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>The increasing availability of graph-structured data motivates the task of optimising over functions defined on the node set of graphs. Traditional graph search algorithms can be applied in this case, but they may be sample-inefficient and do not make use of information about the function values; on the other hand, Bayesian optimisation is a class of promising black-box solvers with superior sample efficiency, but it has scarcely been applied to such novel setups. To fill this gap, we propose a novel Bayesian optimisation framework that optimises over functions defined on generic, large-scale and potentially unknown graphs. Through the learning of suitable kernels on graphs, our framework has the advantage of adapting to the behaviour of the target function. The local modelling approach further guarantees the efficiency of our method. Extensive experiments on both synthetic and real-world graphs demonstrate the effectiveness of the proposed optimisation framework.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">EMNLP 2023</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="zhou-etal-2023-survival" class="col-sm-8">
    <!-- Title -->
    <div class="title">Survival of the Most Influential Prompts: Efficient Black-Box Prompt Search via Clustering and Pruning</div>
    <!-- Author -->
    <div class="author">
      

      
      Han
            Zhou<sup>*</sup>, <em>Xingchen
            Wan<sup>*</sup></em>, Ivan
            Vuliƒá, and Anna
            Korhonen
      
        <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* equal contribution">
        </i>
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>In Findings of the Association for Computational Linguistics: EMNLP 2023</em>,  2023
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
        
          <a href="https://aclanthology.org/2023.findings-emnlp.870.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
        <a href="https://github.com/cambridgeltl/ClaPS" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
        <div class="badges">
          
          
          
            <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=6KkohssAAAAJ&amp;citation_for_view=6KkohssAAAAJ:35N4QoGY0k4C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
              <img src="https://img.shields.io/badge/scholar-29-4285F4?logo=googlescholar&amp;labelColor=beige" alt="29 Google Scholar citations">
            </a>
          
          
        </div>
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Prompt-based learning has been an effective paradigm for large pretrained language models (LLM), enabling few-shot or even zero-shot learning. Black-box prompt search has received growing interest recently for its distinctive properties of gradient-free optimization, proven particularly useful and powerful for model-as-a-service usage. However, the discrete nature and the complexity of combinatorial optimization hinder the efficiency of modern black-box approaches. Despite extensive research on search algorithms, the crucial aspect of search space design and optimization has been largely overlooked. In this paper, we first conduct a sensitivity analysis by prompting LLM, revealing that only a small number of tokens exert a disproportionate amount of influence on LLM predictions. Leveraging this insight, we propose the Clustering and Pruning for Efficient Black-box Prompt Search (ClaPS), a simple black-box search method that first clusters and prunes the search space to focus exclusively on influential prompt tokens. By employing even simple search methods within the pruned search space, ClaPS achieves state-of-the-art performance across various tasks and LLMs, surpassing the performance of complex approaches while significantly reducing search costs. Our findings underscore the critical role of search space design and optimization in enhancing both the usefulness and the efficiency of black-box prompt-based learning.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">EMNLP 2023</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="wan-etal-2023-universal" class="col-sm-8">
    <!-- Title -->
    <div class="title">Universal Self-Adaptive Prompting</div>
    <!-- Author -->
    <div class="author">
      

      
      <em>Xingchen
            Wan</em>, Ruoxi
            Sun, Hootan
            Nakhost, Hanjun
            Dai, Julian Martin
            Eisenschlos, Sercan √ñ.
            Arƒ±k, and Tomas
            Pfister
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>. üìù <strong>Featured in <a href="https://research.google/blog/zero-shot-adaptive-prompting-of-large-language-models/" rel="external nofollow noopener" target="_blank">Google Research Blog</a></strong>
,  2023
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
        
          <a href="https://aclanthology.org/2023.emnlp-main.461.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
        <div class="badges">
          
          
          
            <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=6KkohssAAAAJ&amp;citation_for_view=6KkohssAAAAJ:NMxIlDl6LWMC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
              <img src="https://img.shields.io/badge/scholar-31-4285F4?logo=googlescholar&amp;labelColor=beige" alt="31 Google Scholar citations">
            </a>
          
          
        </div>
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>A hallmark of modern large language models (LLMs) is their impressive general zero-shot and few-shot abilities, often elicited through in-context learning (ICL) via prompting. However, while highly coveted and being the most general, zero-shot performances in LLMs are still typically weaker due to the lack of guidance and the difficulty of applying existing automatic prompt design methods in general tasks when ground-truth labels are unavailable. In this study, we address this by presenting Universal Self-Adaptive Prompting (USP), an automatic prompt design approach specifically tailored for zero-shot learning (while compatible with few-shot). Requiring only a small amount of unlabeled data and an inference-only LLM, USP is highly versatile: to achieve universal prompting, USP categorizes a possible NLP task into one of the three possible task types and then uses a corresponding selector to select the most suitable queries and zero-shot model-generated responses as pseudo-demonstrations, thereby generalizing ICL to the zero-shot setup in a fully automated way. We evaluate USP with PaLM and PaLM 2 models and demonstrate performances that are considerably stronger than standard zero-shot baselines and often comparable to or even superior to few-shot baselines across more than 40 natural language understanding, natural language generation, and reasoning tasks.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">TMLR 2023</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="hamid2023bayesian" class="col-sm-8">
    <!-- Title -->
    <div class="title">Bayesian Quadrature for Neural Ensemble Search</div>
    <!-- Author -->
    <div class="author">
      

      
      Saad
            Hamid, <em>Xingchen
            Wan</em>, Martin
            J√∏rgensen, Binxin
            Ru, and Michael A
            Osborne
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>Transactions on Machine Learning Research</em>,  2023
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
        
          <a href="https://arxiv.org/pdf/2303.08874" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
        <a href="https://github.com/saadhamidml/bq-nes" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
        <div class="badges">
          
          
          
            <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=6KkohssAAAAJ&amp;citation_for_view=6KkohssAAAAJ:maZDTaKrznsC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
              <img src="https://img.shields.io/badge/scholar-2-4285F4?logo=googlescholar&amp;labelColor=beige" alt="2 Google Scholar citations">
            </a>
          
          
        </div>
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Ensembling can improve the performance of Neural Networks, but existing approaches struggle when the architecture likelihood surface has dispersed, narrow peaks. Furthermore, existing methods construct equally weighted ensembles, and this is likely to be vulnerable to the failure modes of the weaker architectures. By viewing ensembling as approximately marginalising over architectures we construct ensembles using the tools of Bayesian Quadrature ‚Äì tools which are well suited to the exploration of likelihood surfaces with dispersed, narrow peaks. Additionally, the resulting ensembles consist of architectures weighted commensurate with their performance. We show empirically ‚Äì in terms of test likelihood, accuracy, and expected calibration error ‚Äì that our method outperforms state-of-the-art baselines, and verify via ablation studies that its components do so independently.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">ACL 2023</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="wan-etal-2023-better" class="col-sm-8">
    <!-- Title -->
    <div class="title">Better Zero-Shot Reasoning with Self-Adaptive Prompting</div>
    <!-- Author -->
    <div class="author">
      

      
      <em>Xingchen
            Wan</em>, Ruoxi
            Sun, Hanjun
            Dai, Sercan √ñ.
            Arƒ±k, and Tomas
            Pfister
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>In Findings of the Association for Computational Linguistics: ACL 2023</em>. üìù <strong>Featured in <a href="https://research.google/blog/zero-shot-adaptive-prompting-of-large-language-models/" rel="external nofollow noopener" target="_blank">Google Research Blog</a></strong>
,  2023
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
        
          <a href="https://aclanthology.org/2023.findings-acl.216.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
        <div class="badges">
          
          
          
            <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=6KkohssAAAAJ&amp;citation_for_view=6KkohssAAAAJ:YFjsv_pBGBYC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
              <img src="https://img.shields.io/badge/scholar-79-4285F4?logo=googlescholar&amp;labelColor=beige" alt="79 Google Scholar citations">
            </a>
          
          
        </div>
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Modern large language models (LLMs) have demonstrated impressive capabilities at sophisticated tasks, often through step-by-step reasoning similar to humans. This is made possible by their strong few-and zero-shot abilities‚Äìthey can effectively learn from a handful of handcrafted, completed responses (‚Äúin-context examples‚Äù), or are prompted to reason spontaneously through specially designed triggers. Nonetheless, some limitations have been observed. First, performance in the few-shot setting is sensitive to the choice of the examples, whose design requires significant human effort. Moreover, given the diverse downstream tasks of LLMs, it may be difficult or laborious to handcraft per-task labels. Second, while the zero-shot setting does not require handcrafting, its performance is limited due to the lack of guidance to the LLMs. To address these limitations, we propose Consistency-based Self-adaptive Prompting (COSP), a novel prompt design method for LLMs. Requiring neither handcrafted responses nor ground-truth labels, COSP selects and builds the set of examples from the LLM zero-shot outputs via carefully designed criteria combining consistency, diversity and repetition. In the zero-shot setting for three different LLMs, we show that using only LLM predictions, COSP significantly improves performance up to 15% compared to zero-shot baselines and matches or exceeds few-shot baselines at a range of reasoning tasks.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100" style="background-color:#00369f">
            
              <a href="https://arXiv.org" rel="external nofollow noopener" target="_blank">arXiv</a>
            
          </abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="li2023simsc" class="col-sm-8">
    <!-- Title -->
    <div class="title">SimSC: A Simple Framework for Semantic Correspondence with Temperature Learning</div>
    <!-- Author -->
    <div class="author">
      

      
      Xinghui
            Li, Kai
            Han, <em>Xingchen
            Wan</em>, and Victor Adrian
            Prisacariu
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>arXiv preprint arXiv:2305.02385</em>,  2023
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
        
          <a href="https://arxiv.org/pdf/2305.02385" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
        <div class="badges">
          
          
          
            <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=6KkohssAAAAJ&amp;citation_for_view=6KkohssAAAAJ:hMod-77fHWUC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
              <img src="https://img.shields.io/badge/scholar-6-4285F4?logo=googlescholar&amp;labelColor=beige" alt="6 Google Scholar citations">
            </a>
          
          
        </div>
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>We propose SimSC, a remarkably simple framework, to address the problem of semantic matching only based on the feature backbone. We discover that when fine-tuning ImageNet pre-trained backbone on the semantic matching task, L2 normalization of the feature map, a standard procedure in feature matching, produces an overly smooth matching distribution and significantly hinders the fine-tuning process. By setting an appropriate temperature to the softmax, this over-smoothness can be alleviated and the quality of features can be substantially improved. We employ a learning module to predict the optimal temperature for fine-tuning feature backbones. This module is trained together with the backbone and the temperature is updated online. We evaluate our method on three public datasets and demonstrate that we can achieve accuracy on par with state-of-the-art methods under the same backbone without using a learned matching head. Our method is versatile and works on various types of backbones. We show that the accuracy of our framework can be easily improved by coupling it with more powerful backbones.</p>
      </div>
    

    

    
  </div>
</div>
</li>
</ol>
<h2 class="bibliography">2022</h2>
<ol class="bibliography">
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">NeurIPS 2022</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="daulton2022pr" class="col-sm-8">
    <!-- Title -->
    <div class="title">Bayesian Optimization over Discrete and Mixed Spaces via Probabilistic Reparameterization</div>
    <!-- Author -->
    <div class="author">
      

      
      Samuel
            Daulton, <em>Xingchen
            Wan</em>, David
            Eriksson, Maximilian
            Balandat, Michael A
            Osborne, and Eytan
            Bakshy
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>In Advances in Neural Information Processing Systems 35 (NeurIPS 2022)</em>,  2022
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
        
          <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/531230cfac80c65017ad0f85d3031edc-Paper-Conference.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
        <a href="https://github.com/facebookresearch/bo_pr" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
        <div class="badges">
          
          
          
            <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=6KkohssAAAAJ&amp;citation_for_view=6KkohssAAAAJ:R3hNpaxXUhUC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
              <img src="https://img.shields.io/badge/scholar-87-4285F4?logo=googlescholar&amp;labelColor=beige" alt="87 Google Scholar citations">
            </a>
          
          
        </div>
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Optimizing expensive-to-evaluate black-box functions of discrete (and potentially continuous) design parameters is a ubiquitous problem in scientific and engineering applications. Bayesian optimization (BO) is a popular, sample-efficient method that leverages a probabilistic surrogate model and an acquisition function (AF) to select promising designs to evaluate. However, maximizing the AF over mixed or high-cardinality discrete search spaces is challenging standard gradient-based methods cannot be used directly or evaluating the AF at every point in the search space would be computationally prohibitive. To address this issue, we propose using probabilistic reparameterization (PR). Instead of directly optimizing the AF over the search space containing discrete parameters, we instead maximize the expectation of the AF over a probability distribution defined by continuous parameters. We prove that under suitable reparameterizations, the BO policy that maximizes the probabilistic objective is the same as that which maximizes the AF, and therefore, PR enjoys the same regret bounds as the original BO policy using the underlying AF. Moreover, our approach provably converges to a stationary point of the probabilistic objective under gradient ascent using scalable, unbiased estimators of both the probabilistic objective and its gradient. Therefore, as the number of starting points and gradient steps increase, our approach will recover of a maximizer of the AF (an often-neglected requisite for commonly used BO regret bounds). We validate our approach empirically and demonstrate state-of-the-art optimization performance on a wide range of real ‚Ä¶</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">AutoML-Conf 2022</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="wan2022bayesian" class="col-sm-8">
    <!-- Title -->
    <div class="title">Bayesian Generational Population-Based Training</div>
    <!-- Author -->
    <div class="author">
      

      
      <em>Xingchen
            Wan</em>, Cong
            Lu, Jack
            Parker-Holder, Philip J
            Ball, Vu
            Nguyen, Binxin
            Ru, and Michael A
            Osborne
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>In Proceedings of the First International Conference on Automated Machine Learning (AutoML-Conf)</em>,  2022
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
        
          <a href="https://proceedings.mlr.press/v188/wan22a/wan22a.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
        <a href="https://github.com/xingchenwan/bgpbt" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
        <div class="badges">
          
          
          
            <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=6KkohssAAAAJ&amp;citation_for_view=6KkohssAAAAJ:k_IJM867U9cC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
              <img src="https://img.shields.io/badge/scholar-31-4285F4?logo=googlescholar&amp;labelColor=beige" alt="31 Google Scholar citations">
            </a>
          
          
        </div>
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Reinforcement learning (RL) offers the potential for training generally capable agents that can interact autonomously in the real world. However, one key limitation is the brittleness of RL algorithms to core hyperparameters and network architecture choice. Furthermore, non-stationarities such as evolving training data and increased agent complexity mean that different hyperparameters and architectures may be optimal at different points of training. This motivates AutoRL, a class of methods seeking to automate these design choices. One prominent class of AutoRL methods is Population-Based Training (PBT), which have led to impressive performance in several large scale settings. In this paper, we introduce two new innovations in PBT-style methods. First, we employ trust-region based Bayesian Optimization, enabling full coverage of the high-dimensional mixed hyperparameter search space. Second, we show that using a generational approach, we can also learn both architectures and hyperparameters jointly on-the-fly in a single training run. Leveraging the new highly parallelizable Brax physics engine, we show that these innovations lead to dramatic performance gains, significantly outperforming the tuned baseline while learning entire configurations on the fly.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">ICLR 2022</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="wan2022on" class="col-sm-8">
    <!-- Title -->
    <div class="title">On Redundancy and Diversity in Cell-based Neural Architecture Search</div>
    <!-- Author -->
    <div class="author">
      

      
      <em>Xingchen
            Wan</em>, Binxin
            Ru, Pedro M
            Esperan√ßa, and Zhenguo
            Li
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>In International Conference on Learning Representations (ICLR)</em>,  2022
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
        
          <a href="https://openreview.net/pdf?id=rFJWoYoxrDB" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
        <a href="https://github.com/xingchenwan/cell-based-NAS-analysis" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
        <div class="badges">
          
          
          
            <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=6KkohssAAAAJ&amp;citation_for_view=6KkohssAAAAJ:dhFuZR0502QC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
              <img src="https://img.shields.io/badge/scholar-36-4285F4?logo=googlescholar&amp;labelColor=beige" alt="36 Google Scholar citations">
            </a>
          
          
        </div>
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Searching for the architecture cells is a dominant paradigm in NAS. However, little attention has been devoted to the analysis of the cell-based search spaces even though it is highly important for the continual development of NAS. In this work, we conduct an empirical post-hoc analysis of architectures from the popular cell-based search spaces and find that the existing search spaces contain a high degree of redundancy: the architecture performance is minimally sensitive to changes at large parts of the cells, and universally adopted designs, like the explicit search for a reduction cell, significantly increase the complexities but have very limited impact on the performance. Across architectures found by a diverse set of search strategies, we consistently find that the parts of the cells that do matter for architecture performance often follow similar and simple patterns. By explicitly constraining cells to include these patterns, randomly sampled architectures can match or even outperform the state of the art. These findings cast doubts into our ability to discover truly novel architectures in the existing cell-based search spaces, and inspire our suggestions for improvement to guide future NAS research. Code is available at https://github.com/xingchenwan/cell-based-NAS-analysis.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">DATE 2022</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="grosnit2022boils" class="col-sm-8">
    <!-- Title -->
    <div class="title">Bayesian Optimisation for Logic Synthesis</div>
    <!-- Author -->
    <div class="author">
      

      
      Antoine
            Grosnit<sup>*</sup>, Cedric
            Malherbe<sup>*</sup>, Rasul
            Tutunov, <em>Xingchen
            Wan</em>, Jun
            Wang, and Haitham
            Bou Ammar
      
        <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* equal contribution">
        </i>
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>In Proceedings of the 2022 Design, Automation and Test in Europe Conference (DATE)</em>,  2022
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
        
          <a href="https://arxiv.org/pdf/2111.06178" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
        <div class="badges">
          
          
          
            <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=6KkohssAAAAJ&amp;citation_for_view=6KkohssAAAAJ:qxL8FJ1GzNcC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
              <img src="https://img.shields.io/badge/scholar-65-4285F4?logo=googlescholar&amp;labelColor=beige" alt="65 Google Scholar citations">
            </a>
          
          
        </div>
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Optimising the quality-of-results (QoR) of circuits during logic synthesis is a formidable challenge necessitating the exploration of exponentially sized search spaces. While expert-designed operations aid in uncovering effective sequences, the increase in complexity of logic circuits favours automated procedures. To enable efficient and scalable solvers, we propose BOiLS, the first algorithm adapting Bayesian optimisation to navigate the space of synthesis operations. BOiLS requires no human intervention and trades-off exploration versus exploitation through novel Gaussian process kernels and trust-region constrained acquisitions. In a set of experiments on EPFL benchmarks, we demonstrate BOiLS‚Äôs superior performance compared to state-of-the-art in terms of both sample efficiency and QoR values.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">WACV 2022</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="wan2022approximate" class="col-sm-8">
    <!-- Title -->
    <div class="title">Approximate Neural Architecture Search via Operation Distribution Learning</div>
    <!-- Author -->
    <div class="author">
      

      
      <em>Xingchen
            Wan</em>, Binxin
            Ru, Pedro M
            Esperan√ßa, and Fabio M
            Carlucci
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</em>,  2022
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
        
          <a href="https://openaccess.thecvf.com/content/WACV2022/papers/Wan_Approximate_Neural_Architecture_Search_via_Operation_Distribution_Learning_WACV_2022_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
        <div class="badges">
          
          
          
            <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=6KkohssAAAAJ&amp;citation_for_view=6KkohssAAAAJ:_kc_bZDykSQC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
              <img src="https://img.shields.io/badge/scholar-15-4285F4?logo=googlescholar&amp;labelColor=beige" alt="15 Google Scholar citations">
            </a>
          
          
        </div>
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>The standard paradigm in neural architecture search (NAS) is to search for a fully deterministic architecture with specific operations and connections. In this work, we instead propose to search for the optimal operation distribution, thus providing a stochastic and approximate solution, which can be used to sample architectures of arbitrary length. We propose and show, that given an architectural cell, its performance largely depends on the ratio of used operations, rather than any specific connection pattern; that is, small changes in the ordering of the operations are often irrelevant. This intuition is orthogonal to any specific search strategy and can be applied to a diverse set of NAS algorithms. Through extensive validation on 4 data-sets and 4 NAS techniques (Bayesian optimisation, differentiable search, local search and random search), we show that the operation distribution (1) holds enough discriminating power to reliably identify a solution and (2) is significantly easier to optimise than traditional encodings, leading to large speed-ups at little to no cost in performance. Indeed, this simple intuition significantly reduces the cost of current approaches and potentially enable NAS to be used in a broader range of research applications.</p>
      </div>
    

    

    
  </div>
</div>
</li>
</ol>
<h2 class="bibliography">2021</h2>
<ol class="bibliography">
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">ICLR 2021</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="ru2021interpretable" class="col-sm-8">
    <!-- Title -->
    <div class="title">Interpretable Neural Architecture Search via Bayesian Optimisation with Weisfeiler-Lehman Kernels</div>
    <!-- Author -->
    <div class="author">
      

      
      Binxin
            Ru<sup>*</sup>, <em>Xingchen
            Wan<sup>*</sup></em>, Xiaowen
            Dong, and Michael
            Osborne
      
        <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* equal contribution">
        </i>
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>In International Conference on Learning Representations</em>,  2021
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
        
          <a href="https://openreview.net/pdf?id=j9Rv7qdXjd" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
        <a href="https://github.com/xingchenwan/nasbowl" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
        <div class="badges">
          
          
          
            <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=6KkohssAAAAJ&amp;citation_for_view=6KkohssAAAAJ:4JMBOYKVnBMC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
              <img src="https://img.shields.io/badge/scholar-160-4285F4?logo=googlescholar&amp;labelColor=beige" alt="160 Google Scholar citations">
            </a>
          
          
        </div>
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Current neural architecture search (NAS) strategies focus only on finding a single, good, architecture. They offer little insight into why a specific network is performing well, or how we should modify the architecture if we want further improvements. We propose a Bayesian optimisation (BO) approach for NAS that combines the Weisfeiler-Lehman graph kernel with a Gaussian process surrogate. Our method not only optimises the architecture in a highly data-efficient manner, but also affords interpretability by discovering useful network features and their corresponding impact on the network performance. Moreover, our method is capable of capturing the topological structures of the architectures and is scalable to large graphs, thus making the high-dimensional and graph-like search spaces amenable to BO. We demonstrate empirically that our surrogate model is capable of identifying useful motifs which can guide the generation of new architectures. We finally show that our method outperforms existing NAS approaches to achieve the state of the art on both closed- and open-domain search spaces.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">NeurIPS 2021</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="wan2021adversarial" class="col-sm-8">
    <!-- Title -->
    <div class="title">Adversarial Attacks on Graph Classifiers via Bayesian Optimisation</div>
    <!-- Author -->
    <div class="author">
      

      
      <em>Xingchen
            Wan</em>, Henry
            Kenlay, Binxin
            Ru, Arno
            Blaas, Michael
            Osborne, and Xiaowen
            Dong
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>In Advances in Neural Information Processing Systems</em>,  2021
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
        
          <a href="https://proceedings.neurips.cc/paper_files/paper/2021/file/38811c5285e34e2e3319ab7d9f2cfa5b-Paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
        <a href="https://github.com/xingchenwan/grabnel" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
        <div class="badges">
          
          
          
            <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=6KkohssAAAAJ&amp;citation_for_view=6KkohssAAAAJ:M3ejUd6NZC8C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
              <img src="https://img.shields.io/badge/scholar-52-4285F4?logo=googlescholar&amp;labelColor=beige" alt="52 Google Scholar citations">
            </a>
          
          
        </div>
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>Graph neural networks, a popular class of models effective in a wide range of graph-based learning tasks, have been shown to be vulnerable to adversarial attacks. While the majority of the literature focuses on such vulnerability in node-level classification tasks, little effort has been dedicated to analysing adversarial attacks on graph-level classification, an important problem with numerous real-life applications such as biochemistry and social network analysis. The few existing methods often require unrealistic setups, such as access to internal information of the victim models, or an impractically-large number of queries. We present a novel Bayesian optimisation-based attack method for graph classification models. Our method is black-box, query-efficient and parsimonious with respect to the perturbation applied. We empirically validate the effectiveness and flexibility of the proposed method on a wide range of graph classification tasks involving varying graph properties, constraints and modes of attack. Finally, we analyse common interpretable patterns behind the adversarial samples produced, which may shed further light on the adversarial robustness of graph classification models.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">ICML 2021</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="wan2021think" class="col-sm-8">
    <!-- Title -->
    <div class="title">Think Global and Act Local: Bayesian Optimisation over High-Dimensional Categorical and Mixed Search Spaces</div>
    <!-- Author -->
    <div class="author">
      

      
      <em>Xingchen
            Wan</em>, Vu
            Nguyen, Huong
            Ha, Binxin
            Ru, Cong
            Lu, and Michael A
            Osborne
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>In International Conference on Machine Learning (ICML)</em>,  2021
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
        
          <a href="https://arxiv.org/pdf/2102.07188" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
        <a href="https://github.com/xingchenwan/Casmopolitan" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
        <div class="badges">
          
          
          
            <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=6KkohssAAAAJ&amp;citation_for_view=6KkohssAAAAJ:_FxGoFyzp5QC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
              <img src="https://img.shields.io/badge/scholar-110-4285F4?logo=googlescholar&amp;labelColor=beige" alt="110 Google Scholar citations">
            </a>
          
          
        </div>
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>High-dimensional black-box optimisation remains an important yet notoriously challenging problem. Despite the success of Bayesian optimisation methods on continuous domains, domains that are categorical, or that mix continuous and categorical variables, remain challenging. We propose a novel solution ‚Äì we combine local optimisation with a tailored kernel design, effectively handling high-dimensional categorical and mixed search spaces, whilst retaining sample efficiency. We further derive convergence guarantee for the proposed approach. Finally, we demonstrate empirically that our method outperforms the current baselines on a variety of synthetic and real-world tasks in terms of performance, computational costs, or both.</p>
      </div>
    

    

    
  </div>
</div>
</li>
<li>
<div class="row">
  
    <div class="col col-sm-2 abbr">
          <abbr class="badge rounded w-100">Sci. Rep. 11</abbr>
        
      
      
    </div>
  

  <!-- Entry bib key -->
  <div id="wan2021sentiment" class="col-sm-8">
    <!-- Title -->
    <div class="title">Sentiment correlation in financial news networks and associated market movements</div>
    <!-- Author -->
    <div class="author">
      

      
      <em>Xingchen
            Wan<sup>*</sup></em>, Jie
            Yang<sup>*</sup>, Slavi
            Marinov, Jan-Peter
            Calliess, Stefan
            Zohren, and Xiaowen
            Dong
      
        <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* equal contribution">
        </i>
      
    </div>

    <!-- Journal/Book title and date -->
    
    
    
    
    
    
    
    
    
    
    <div class="periodical">
      <em>Scientific reports</em>,  2021
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      
      
        <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
        <a href="https://doi.org/10.1038/s41598-021-82338-6" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a>
      
      
      
      
        
          <a href="https://www.nature.com/articles/s41598-021-82338-6" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
        
      
      
        
          <a href="https://www.nature.com/articles/s41598-021-82338-6.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
        
      
      
      
      
      
        <a href="https://github.com/xingchenwan/SentimentSciRep" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
      
      
      
      
    </div>
    
      
      

      
      

      
      

      
      
      
        <div class="badges">
          
            <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-altmetric-id="94183114"></span>
          
          
            <span class="__dimensions_badge_embed__" data-doi="10.1038/s41598-021-82338-6" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          
          
            <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=6KkohssAAAAJ&amp;citation_for_view=6KkohssAAAAJ:ufrVoPGSRksC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
              <img src="https://img.shields.io/badge/scholar-110-4285F4?logo=googlescholar&amp;labelColor=beige" alt="110 Google Scholar citations">
            </a>
          
          
        </div>
      
    

    

    
      <!-- Hidden abstract block -->
      <div class="abstract hidden">
        <p>In an increasingly connected global market, news sentiment towards one company may not only indicate its own market performance, but can also be associated with a broader movement on the sentiment and performance of other companies from the same or even different sectors. In this paper, we apply NLP techniques to understand news sentiment of 87 companies among the most reported on Reuters for a period of 7 years. We investigate the propagation of such sentiment in company networks and evaluate the associated market movements in terms of stock price and volatility. Our results suggest that, in certain sectors, strong media sentiment towards one company may indicate a significant change in media sentiment towards related companies measured as neighbours in a financial network constructed from news co-occurrence. Furthermore, there exists a weak but statistically significant association between strong media sentiment and abnormal market return as well as volatility. Such an association is more significant at the level of individual companies, but nevertheless remains visible at the level of sectors or groups of companies.</p>
      </div>
    

    

    
  </div>
</div>
</li>
</ol>

</div>

  </article>

  

  
</div>

      
    </div>

    <!-- Footer -->
    


  <footer class="fixed-bottom" role="contentinfo">
    <div class="container mt-0">
      
  ¬© Copyright 2026
  Xingchen
  
  Wan. 
  
  

    </div>
  </footer>



    <!-- JavaScripts -->
    <!-- jQuery -->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

<!-- Bootsrap & MDB scripts -->
<script src="/assets/js/bootstrap.bundle.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>


  <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script>























  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script>






<!-- Load Common JS -->
<script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script>
<script defer src="/assets/js/common.js?c15de51d4bb57887caa2c21988d97279"></script>
<script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script>

<!-- Jupyter Open External Links New Tab -->
<script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script>

<!-- Badges -->

  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>


  <script async src="https://badge.dimensions.ai/badge.js"></script>



  <!-- MathJax -->
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script>
  
    <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script>
    <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script>
  



  <!-- Analytics -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-GHJ9KNNZZB"></script>
  <script defer src="/assets/js/google-analytics-setup.js"></script>







  <!-- Scrolling Progress Bar -->
  <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script>







  <!-- Back to Top -->
  <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script>
  <script>
    addBackToTop();
  </script>



  <!-- Search -->
  <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script>
  <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys>
  <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script>
  <script src="/assets/js/search-data.js"></script>
  <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script>




  </body>
</html>
