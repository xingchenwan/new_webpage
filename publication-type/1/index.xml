<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>1 | Xingchen Wan</title>
    <link>https://xingchen.one/publication-type/1/</link>
      <atom:link href="https://xingchen.one/publication-type/1/index.xml" rel="self" type="application/rss+xml" />
    <description>1</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sat, 11 May 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://xingchen.one/media/icon_huab74be30481f90068f99190f5c24f5c6_21326_512x512_fill_lanczos_center_3.png</url>
      <title>1</title>
      <link>https://xingchen.one/publication-type/1/</link>
    </image>
    
    <item>
      <title>Batch Calibration: Rethinking Calibration for In-Context Learning and Prompt Engineering</title>
      <link>https://xingchen.one/publication/bc/</link>
      <pubDate>Sat, 11 May 2024 00:00:00 +0000</pubDate>
      <guid>https://xingchen.one/publication/bc/</guid>
      <description>&lt;p&gt;















&lt;figure  id=&#34;figure-illustration-of-batch-calibration-bc-batches-of-demonstrations-with-in-context-examples-and-test-samples-are-passed-into-the-llm-due-to-sources-of-implicit-bias-in-the-context-the-score-distribution-from-the-llm-becomes-biased-bc-is-a-modular-and-adaptable-layer-option-appended-to-the-output-of-the-llm-that-generates-calibrated-scores-visualized-for-illustration-only&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Illustration of Batch Calibration (BC). Batches of demonstrations with in-context examples and test samples are passed into the LLM. Due to sources of implicit bias in the context, the score distribution from the LLM becomes biased. BC is a modular and adaptable layer option appended to the output of the LLM that generates calibrated scores (visualized for illustration only)&#34;
           src=&#34;https://xingchen.one/publication/bc/demo.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Illustration of Batch Calibration (BC). Batches of demonstrations with in-context examples and test samples are passed into the LLM. Due to sources of implicit bias in the context, the score distribution from the LLM becomes biased. BC is a modular and adaptable layer option appended to the output of the LLM that generates calibrated scores (visualized for illustration only).
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Adaptive Batch Sizes for Active Learning: A Probabilistic Numerics Approach</title>
      <link>https://xingchen.one/publication/adabatal/</link>
      <pubDate>Sat, 04 May 2024 00:00:00 +0000</pubDate>
      <guid>https://xingchen.one/publication/adabatal/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Working Memory Capacity of ChatGPT: An Empirical Study</title>
      <link>https://xingchen.one/publication/working_memory/</link>
      <pubDate>Thu, 01 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://xingchen.one/publication/working_memory/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Universal Self-Adaptive Prompting</title>
      <link>https://xingchen.one/publication/usp/</link>
      <pubDate>Sun, 24 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://xingchen.one/publication/usp/</guid>
      <description>&lt;p&gt;















&lt;figure  id=&#34;figure-illustration-of-usp-in-exemplary-tasks-classification-qa-and-text-summarization-similar-to-cosp-the-llm-first-generates-predictions-on-an-unlabeled-dataset-whose-outputs-are-scored-with-logit-entropy-consistency-or-alignment-depending-on-the-task-type-and-pseudo-demonstrations-are-selected-from-these-input-output-pairs-in-stage-2-the-test-instances-are-augmented-with-pseudo-demos-for-prediction&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Illustration of USP in exemplary tasks (classification, QA and text summarization). Similar to COSP, the LLM first generates predictions on an unlabeled dataset whose outputs are scored with logit entropy, consistency or alignment, depending on the task type, and pseudo-demonstrations are selected from these input-output pairs. In Stage 2, the test instances are augmented with pseudo-demos for prediction.&#34;
           src=&#34;https://xingchen.one/publication/usp/demo.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Illustration of USP in exemplary tasks (classification, QA and text summarization). Similar to COSP, the LLM first generates predictions on an unlabeled dataset whose outputs are scored with logit entropy, consistency or alignment, depending on the task type, and pseudo-demonstrations are selected from these input-output pairs. In Stage 2, the test instances are augmented with pseudo-demos for prediction.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Survival of the Most Influential Prompts: Efficient Black-Box Prompt Search via Clustering and Pruning</title>
      <link>https://xingchen.one/publication/claps/</link>
      <pubDate>Fri, 15 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://xingchen.one/publication/claps/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Bayesian Optimisation of Functions on Graphs</title>
      <link>https://xingchen.one/publication/bayesoptg/</link>
      <pubDate>Sun, 10 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://xingchen.one/publication/bayesoptg/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Better Zero-Shot Reasoning with Self-Adaptive Prompting</title>
      <link>https://xingchen.one/publication/cosp/</link>
      <pubDate>Sat, 01 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://xingchen.one/publication/cosp/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Bayesian Optimization over Discrete and Mixed Spaces via Probabilistic Reparameterization</title>
      <link>https://xingchen.one/publication/prbo/</link>
      <pubDate>Thu, 22 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://xingchen.one/publication/prbo/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Bayesian Generational Population-Based Training</title>
      <link>https://xingchen.one/publication/bgpbt/</link>
      <pubDate>Sun, 24 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://xingchen.one/publication/bgpbt/</guid>
      <description>&lt;p&gt;A preliminary version of this paper appeared at the ICLR 2022 Workshop on Agent Learning in Open-Endedness (ALOE).&lt;/p&gt;
&lt;p&gt;This work was featured in the &lt;a href=&#34;https://automl-seminars.github.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;AutoML Seminars&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>On Redundancy and Diversity in Cell-based Neural Architecture Search</title>
      <link>https://xingchen.one/publication/postnas/</link>
      <pubDate>Fri, 29 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://xingchen.one/publication/postnas/</guid>
      <description></description>
    </item>
    
    <item>
      <title>BOiLS: Bayesian Optimisation for Logic Synthesis</title>
      <link>https://xingchen.one/publication/boils/</link>
      <pubDate>Sun, 06 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://xingchen.one/publication/boils/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Approximate Neural Architecture Search via Operation Distribution Learning</title>
      <link>https://xingchen.one/publication/anasod/</link>
      <pubDate>Wed, 05 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://xingchen.one/publication/anasod/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Adversarial Attacks on Graph Classifiers via Bayesian Optimisation</title>
      <link>https://xingchen.one/publication/graphattack/</link>
      <pubDate>Mon, 06 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://xingchen.one/publication/graphattack/</guid>
      <description>&lt;p&gt;A preliminary version of this paper appeared at the ICML 2021 Workshop on Adversarial Machine Learning.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Think Global and Act Local: Bayesian Optimisation over High-Dimensional Categorical and Mixed Search Spaces</title>
      <link>https://xingchen.one/publication/casmopolitan/</link>
      <pubDate>Sat, 24 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://xingchen.one/publication/casmopolitan/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Interpretable Neural Architecture Search via Bayesian Optimisation with Weisfeiler-Lehman Kernels</title>
      <link>https://xingchen.one/publication/nasbowl/</link>
      <pubDate>Fri, 07 May 2021 00:00:00 +0000</pubDate>
      <guid>https://xingchen.one/publication/nasbowl/</guid>
      <description>&lt;p&gt;This work was also presented at the &lt;a href=&#34;https://automl-seminars.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;AutoML seminar&lt;/a&gt; on 3 Dec 2020.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
